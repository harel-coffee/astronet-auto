{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Transformer [`t2`]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Hyperparamter Optimisation of Time Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will investigate the usefulness of TensorFlow's `HParams` hyperparamter optimisation functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example has been taken from the [Hyperparameter Tuning with the HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) documentation page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"./logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "  model.fit(x_train, y_train, epochs=1, \n",
    "           callbacks=[\n",
    "            tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "            hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "        ]) # Run with 1 epoch to speed things up for demo purposes\n",
    "  _, accuracy = model.evaluate(x_test, y_test)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.3635 - accuracy: 0.0938WARNING:tensorflow:From /usr/local/anaconda3/envs/astronet/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0117s). Check your callbacks.\n",
      "1875/1875 [==============================] - 2s 941us/step - loss: 0.6728 - accuracy: 0.7703\n",
      "313/313 [==============================] - 0s 594us/step - loss: 0.5028 - accuracy: 0.8193\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.3706 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0262s). Check your callbacks.\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.9954 - accuracy: 0.6557\n",
      "313/313 [==============================] - 0s 608us/step - loss: 0.6780 - accuracy: 0.7690\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.4404 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0295s). Check your callbacks.\n",
      "1875/1875 [==============================] - 2s 879us/step - loss: 0.7651 - accuracy: 0.7250\n",
      "313/313 [==============================] - 0s 589us/step - loss: 0.5039 - accuracy: 0.8185\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.2700 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0253s). Check your callbacks.\n",
      "1875/1875 [==============================] - 1s 740us/step - loss: 1.0493 - accuracy: 0.6364\n",
      "313/313 [==============================] - 0s 725us/step - loss: 0.6823 - accuracy: 0.7697\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.4655 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0278s). Check your callbacks.\n",
      "1875/1875 [==============================] - 2s 907us/step - loss: 0.6031 - accuracy: 0.7908\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.8392\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.3732 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0261s). Check your callbacks.\n",
      "1875/1875 [==============================] - 2s 914us/step - loss: 0.8569 - accuracy: 0.7128\n",
      "313/313 [==============================] - 0s 732us/step - loss: 0.6226 - accuracy: 0.7875\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.4291 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0320s). Check your callbacks.\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.6499 - accuracy: 0.7750\n",
      "313/313 [==============================] - 0s 696us/step - loss: 0.4597 - accuracy: 0.8363\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "   1/1875 [..............................] - ETA: 0s - loss: 2.5063 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0256s). Check your callbacks.\n",
      "1875/1875 [==============================] - 2s 833us/step - loss: 0.9374 - accuracy: 0.6927\n",
      "313/313 [==============================] - 0s 699us/step - loss: 0.6142 - accuracy: 0.7968\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HParams Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a9ccdacadeda7906\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a9ccdacadeda7906\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
