#!/bin/bash
# Copyright 2021
# Author: Tarek Allam Jr.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#SBATCH --job-name=chunkpt              # Job name
#SBATCH --time=48:00:00                 # Time limit hrs:min:sec
#SBATCH --output=logs/%j.log            # Standard output and error log
# #SBATCH --exclusive                     # Request exclusive access to a node
# #SBATCH --cpus-per-task=40              # Number of CPUs per node
# Add a -e or --error with an error file name to separate output and error
# logs. Note this will ignore the --output option if used afterwards
## #SBATCH -e logs/%j.err
## #SBATCH -o logs/%j.out
#SBATCH --array=1
set -o pipefail -e
source $PWD/conf/astronet.conf
# Print the contents of this file to stdout from line 15 onwards
awk 'NR>15' $ASNWD/sbin/chunk-plasticc-test
date
SECONDS=0 # https://stackoverflow.com/a/8903280/4521950
which python
# Test Imports
python -c "import astronet as asn; print(asn.__version__)"
python -c "import tensorflow as tf; print(tf.__version__)"

declare -a arr=(
                "${ASNWD}/data/plasticc/avocado/avo_aug_1.csv"
            )

echo "${arr[SLURM_ARRAY_TASK_ID-1]}"
dataset="${arr[SLURM_ARRAY_TASK_ID-1]}"
# Chunk each file in array list
python $ASNWD/sbin/chunk_plasticc_test.py --file $dataset -o "${ASNWD}/data/plasticc/avocado/"
date
duration=$SECONDS
echo "$(($duration / 60)) minutes and $(($duration % 60)) seconds elapsed."
