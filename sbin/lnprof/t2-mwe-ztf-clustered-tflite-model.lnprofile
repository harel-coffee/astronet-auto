Metal device set to: Apple M1 Pro
0.5.1.dev33+gb326d80
/Users/tallamjr/github/tallamjr/origin/astronet/astronet/__init__.py
30
candid                                     1786156252415010024
schemavsn                                                  3.3
publisher                                                 Fink
objectId                                          ZTF18acmulej
candidate    (2459540.65625, 2, 1786156252415, 19.284673690...
Name: 30, dtype: object
OBJECT ID:1786156252415010024 at INDEX:0
{
    "AGN": 0.001,
    "EB": 0.0,
    "KN": 0.0,
    "M-dwarf": 0.001,
    "Mira": 0.0,
    "RRL": 0.0,
    "SLSN-I": 0.108,
    "SNII": 0.038,
    "SNIa": 0.167,
    "SNIa-91bg": 0.191,
    "SNIax": 0.188,
    "SNIbc": 0.3,
    "TDE": 0.002,
    "mu-Lens-Single": 0.004
}
Wrote profile results to t2-mwe-ztf.py.lprof
Timer unit: 1e-06 s

Total time: 7.59137 s
File: t2-mwe-ztf.py
Function: get_model at line 89

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    89                                           @profile
    90                                           def get_model(model_name: str = "model-23057-1642540624-0.1.dev963+g309c9d8"):
    91                                               # Load pre-trained model
    92         1          4.0      4.0      0.0      model_path = f"{asnwd}/astronet/t2/models/plasticc/{model_name}"
    93
    94         2    7591303.0 3795651.5    100.0      model = tf.keras.models.load_model(
    95         1          0.0      0.0      0.0          model_path,
    96         1         67.0     67.0      0.0          custom_objects={"WeightedLogLoss": WeightedLogLoss()},
    97         1          0.0      0.0      0.0          compile=False,
    98                                               )
    99
   100         1          1.0      1.0      0.0      return model

Total time: 4.67847 s
File: t2-mwe-ztf.py
Function: get_compressed_model at line 103

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   103                                           @profile
   104                                           def get_compressed_model(model_name: str = "23057-1642540624-0.1.dev963+g309c9d8"):
   105                                               # Load pre-trained model
   106         1          1.0      1.0      0.0      model_path = f"{asnwd}/astronet/t2/models/plasticc/{model_name}"
   107
   108         1       3604.0   3604.0      0.1      with zipfile.ZipFile(f"{model_path}.zip", mode="r") as archive:
   109         7         15.0      2.1      0.0          for file in archive.namelist():
   110         6       3506.0    584.3      0.1              archive.extract(file, model_path)
   111
   112         2    4671329.0 2335664.5     99.8      model = tf.keras.models.load_model(
   113         1          0.0      0.0      0.0          model_path,
   114         1         17.0     17.0      0.0          custom_objects={"WeightedLogLoss": WeightedLogLoss()},
   115         1          0.0      0.0      0.0          compile=False,
   116                                               )
   117         1          1.0      1.0      0.0      return model

Total time: 0.17081 s
File: t2-mwe-ztf.py
Function: t2_probs at line 120

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   120                                           @profile
   121                                           def t2_probs(
   122                                               candid: np.int64,
   123                                               jd: np.ndarray,
   124                                               fid: np.ndarray,
   125                                               magpsf: np.int64,
   126                                               sigmapsf: np.int64,
   127                                               model: tf.keras.Model,
   128                                               prettyprint=None,
   129                                           ) -> Dict:
   130                                               """Compute probabilities of alerts in relation to PLAsTiCC classes using the Time-Series
   131                                               Transformer model
   132
   133                                               Parameters
   134                                               ----------
   135                                               candid: np.int64,
   136                                                   Candidate IDs
   137                                               jd: np.ndarray,
   138                                                   JD times (float)
   139                                               fid: np.ndarray,
   140                                                   Filter IDs (int)
   141                                               magpsf: np.ndarray,
   142                                                   Magnitude from PSF-fit photometry
   143                                               sigmapsf: np.ndarray,
   144                                                   1-sigma error of PSF-fit
   145                                               model: tensorflow.python.keras.saving.saved_model.load.T2Model
   146                                                   Pre-compiled T2 model
   147
   148                                               Returns
   149                                               ----------
   150                                               probabilities: dict
   151                                                   Dict containing np.array of float probabilities
   152
   153                                               Examples
   154                                               ----------
   155                                               >>> import pyspark.pandas as ps
   156                                               >>> psdf = ps.read_parquet('sample.parquet')
   157                                               >>> import random
   158                                               >>> r = random.randint(0,len(psdf))
   159                                               >>> alert = psdf.iloc[r]
   160                                               >>> print(alert.head())
   161                                               candid                                     1786552611115010001
   162                                               schemavsn                                                  3.3
   163                                               publisher                                                 Fink
   164                                               objectId                                          ZTF18aaqfhlj
   165                                               candidate    (2459541.0526157, 2, 1786552611115, 19.1966800...
   166                                               Name: 221, dtype: object
   167                                               >>> alert = alert.to_dict()
   168
   169                                               >>> from fink_client.visualisation import extract_field
   170                                               # Get flux and error
   171                                               >>> magpsf = extract_field(alert, 'magpsf')
   172                                               >>> sigmapsf = extract_field(alert, 'sigmapsf')
   173
   174                                               >>> jd = extract_field(alert, "jd")
   175
   176                                               # For rescaling dates to start at 0 --> 30
   177                                               # dates = np.array([jd[0] - i for i in jd])
   178
   179                                               # FINK candidate ID (int64)
   180                                               >>> candid = alert["candid"]
   181
   182                                               # filter bands
   183                                               >>> fid = extract_field(alert, "fid")
   184
   185                                               >>> model_name = "23057-1642540624-0.1.dev963+g309c9d8"
   186                                               >>> model = get_model(model_name=model_name)
   187
   188                                               >>> t2_probs(candid, jd, fid, magpsf, sigmapsf, model)
   189                                               {
   190                                                   "AGN": 0.0,
   191                                                   "EB": 0.017,
   192                                                   "KN": 0.0,
   193                                                   "M-dwarf": 0.891,
   194                                                   "Mira": 0.002,
   195                                                   "RRL": 0.004,
   196                                                   "SLSN-I": 0.0,
   197                                                   "SNII": 0.078,
   198                                                   "SNIa": 0.001,
   199                                                   "SNIa-91bg": 0.006,
   200                                                   "SNIax": 0.001,
   201                                                   "SNIbc": 0.001,
   202                                                   "TDE": 0.0,
   203                                                   "mu-Lens-Single": 0.0
   204                                               }
   205                                               """
   206
   207         1          2.0      2.0      0.0      ZTF_FILTER_MAP = {1: "ztfg", 2: "ztfr", 3: "ztfi"}
   208
   209         1          1.0      1.0      0.0      ZTF_PB_WAVELENGTHS = {
   210         1          1.0      1.0      0.0          "ztfg": 4804.79,
   211         1          1.0      1.0      0.0          "ztfr": 6436.92,
   212         1          1.0      1.0      0.0          "ztfi": 7968.22,
   213                                               }
   214
   215                                               # Rescale dates to _start_ at 0
   216         1         17.0     17.0      0.0      dates = np.array([jd[0] - i for i in jd])
   217
   218         1          4.0      4.0      0.0      mjd, flux, flux_error, filters = ([] for i in range(4))
   219
   220                                               # Loop over each filter
   221         1          1.0      1.0      0.0      filter_color = ZTF_FILTER_MAP
   222         4          5.0      1.2      0.0      for filt in filter_color.keys():
   223         3         34.0     11.3      0.0          mask = np.where(fid == filt)[0]
   224
   225                                                   # Skip if no data
   226         3          4.0      1.3      0.0          if len(mask) == 0:
   227         1          1.0      1.0      0.0              continue
   228
   229         2         18.0      9.0      0.0          maskNotNone = magpsf[mask] != None
   230         2          8.0      4.0      0.0          mjd.append(dates[mask][maskNotNone])
   231         2          3.0      1.5      0.0          flux.append(magpsf[mask][maskNotNone])
   232         2          3.0      1.5      0.0          flux_error.append(sigmapsf[mask][maskNotNone])
   233         2          2.0      1.0      0.0          filters.append(filt)
   234
   235         2        869.0    434.5      0.5      df_tmp = pd.DataFrame.from_dict(
   236         1          2.0      2.0      0.0          {
   237         1          1.0      1.0      0.0              "mjd": mjd,
   238         1          2.0      2.0      0.0              "object_id": candid,
   239         1          1.0      1.0      0.0              "flux": flux,
   240         1          1.0      1.0      0.0              "flux_error": flux_error,
   241         1          1.0      1.0      0.0              "filters": filters,
   242                                                   }
   243                                               )
   244
   245         1       2889.0   2889.0      1.7      df_tmp = df_tmp.apply(pd.Series.explode).reset_index()
   246
   247                                               # Re-compute flux and flux error
   248         2         32.0     16.0      0.0      data = [
   249                                                   mag2fluxcal_snana(*args)
   250         1        345.0    345.0      0.2          for args in zip(df_tmp["flux"].explode(), df_tmp["flux_error"].explode())
   251                                               ]
   252         1         25.0     25.0      0.0      flux, error = np.transpose(data)
   253
   254                                               # make a Pandas DataFrame with exploded series
   255         2        463.0    231.5      0.3      pdf = pd.DataFrame.from_dict(
   256         1          1.0      1.0      0.0          {
   257         1        596.0    596.0      0.3              "filter": df_tmp["filters"].replace({1: "ztfg", 2: "ztfr"}),
   258         1          2.0      2.0      0.0              "flux": flux,
   259         1          1.0      1.0      0.0              "flux_error": error,
   260         1         42.0     42.0      0.0              "mjd": df_tmp["mjd"],
   261         1         36.0     36.0      0.0              "object_id": df_tmp["object_id"],
   262                                                   }
   263                                               )
   264
   265         1        559.0    559.0      0.3      pdf = pdf.filter(["object_id", "mjd", "flux", "flux_error", "filter"])
   266                                               # pdf = pdf.dropna()
   267                                               # pdf = pdf.reset_index()
   268
   269         1          2.0      2.0      0.0      if not isinstance(candid, list):
   270         1          1.0      1.0      0.0          object_list = [candid]
   271         2      28572.0  14286.0     16.7      df_gp_mean = generate_gp_all_objects(
   272         1          1.0      1.0      0.0          object_list, pdf, pb_wavelengths=ZTF_PB_WAVELENGTHS
   273                                               )
   274
   275         1          8.0      8.0      0.0      cols = set(list(ZTF_PB_WAVELENGTHS.keys())) & set(df_gp_mean.columns)
   276         1     122053.0 122053.0     71.5      robust_scale(df_gp_mean, cols)
   277         1      13029.0  13029.0      7.6      X = df_gp_mean[cols]
   278         1         28.0     28.0      0.0      X = np.asarray(X).astype("float32")
   279         1         20.0     20.0      0.0      X = np.expand_dims(X, axis=0)
   280
   281         1        867.0    867.0      0.5      y_preds = model.predict(X)
   282
   283         1          1.0      1.0      0.0      class_names = [
   284         1          1.0      1.0      0.0          "mu-Lens-Single",
   285         1          1.0      1.0      0.0          "TDE",
   286         1          1.0      1.0      0.0          "EB",
   287         1          1.0      1.0      0.0          "SNII",
   288         1          1.0      1.0      0.0          "SNIax",
   289         1          1.0      1.0      0.0          "Mira",
   290         1          2.0      2.0      0.0          "SNIbc",
   291         1          1.0      1.0      0.0          "KN",
   292         1          1.0      1.0      0.0          "M-dwarf",
   293         1          1.0      1.0      0.0          "SNIa-91bg",
   294         1          1.0      1.0      0.0          "AGN",
   295         1          2.0      2.0      0.0          "SNIa",
   296         1          1.0      1.0      0.0          "RRL",
   297         1          1.0      1.0      0.0          "SLSN-I",
   298                                               ]
   299
   300         1          1.0      1.0      0.0      keys = class_names
   301         1          3.0      3.0      0.0      values = y_preds.tolist()
   302         1          5.0      5.0      0.0      predictions = dict(zip(keys, values[0]))
   303
   304         1          2.0      2.0      0.0      if prettyprint is not None:
   305         1          2.0      2.0      0.0          import json
   306
   307         2          5.0      2.5      0.0          print(
   308         2        122.0     61.0      0.1              json.dumps(
   309         2         45.0     22.5      0.0                  json.loads(
   310         1         49.0     49.0      0.0                      json.dumps(predictions), parse_float=lambda x: round(float(x), 3)
   311                                                           ),
   312         1          1.0      1.0      0.0                  indent=4,
   313         1          1.0      1.0      0.0                  sort_keys=True,
   314                                                       )
   315                                                   )
   316
   317         1          2.0      2.0      0.0      return predictions


systemMemory: 32.00 GB
maxCacheSize: 10.67 GB

